{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "torch.backends.cudnn.benchmark = False\n",
    "UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:34.962559Z",
     "start_time": "2024-03-17T13:12:33.154552Z"
    }
   },
   "id": "b0570a3e0c8f1240"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from utils import BertDataConfig, BertDataset\n",
    "# \n",
    "# data_config = BertDataConfig()\n",
    "# val_dataset = BertDataset(data_config, data_class='val')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T14:30:18.426679400Z",
     "start_time": "2023-12-14T14:30:18.415171900Z"
    }
   },
   "id": "cda7eed9a6f00df6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import DataConfig\n",
    "\n",
    "data_config = DataConfig('word2vec', 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:41.996797Z",
     "start_time": "2024-03-17T13:12:41.380420Z"
    }
   },
   "id": "af892feebfe7d54d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ModelConfig(object):\n",
    "    \"\"\"配置参数\"\"\"\n",
    "\n",
    "    def __init__(self, freeze, notes=''):\n",
    "        self.model_name = 'ShipRNN'\n",
    "        self.save_path = f'./result/{self.model_name}_{notes}.ckpt'  # 模型训练结果\n",
    "        self.log_path = './tf_log/' + self.model_name\n",
    "\n",
    "        self.dropout = 0.5  # 随机失活\n",
    "        self.hidden_size = 256  # lstm隐藏层\n",
    "        self.num_layers = 2  # lstm层数\n",
    "        self.num_heads = 6\n",
    "        self.freeze = freeze\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_config, data_config):\n",
    "        super(Model, self).__init__()\n",
    "        # Existing code\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            data_config.embedding_pretrained,\n",
    "            freeze=model_config.freeze) if data_config.embedding_pretrained is not None else nn.Embedding(\n",
    "            data_config.n_vocab,\n",
    "            data_config.embed,\n",
    "            padding_idx=data_config.n_vocab - 1)\n",
    "        # New BatchNorm layer after embedding\n",
    "        self.ln_after_embedding = nn.LayerNorm(data_config.embed)\n",
    "\n",
    "        self.lstm = nn.LSTM(data_config.embed, model_config.hidden_size, model_config.num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=model_config.dropout)\n",
    "        self.avg_pool = nn.AvgPool1d(data_config.pad_size // 4)\n",
    "        self.value = ((\n",
    "                              model_config.hidden_size * 2 + data_config.embed) // model_config.num_heads) * model_config.num_heads\n",
    "        self.mutilatte = nn.MultiheadAttention(embed_dim=self.value,\n",
    "                                               num_heads=model_config.num_heads,\n",
    "                                               batch_first=True)\n",
    "\n",
    "        self.ln_after_mutilatte = nn.LayerNorm(self.value)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4 * self.value, data_config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)  # [batch_size, seq_len, embeding]\n",
    "        embed = self.ln_after_embedding(embed)  # Apply BN after embedding\n",
    "        out, _ = self.lstm(embed)  # 左右双向\n",
    "        out1 = torch.cat((embed, out), 2)\n",
    "        out1 = F.gelu(out1[:, :, :self.value])\n",
    "        out2, _ = self.mutilatte(out1, out1, out1)\n",
    "        out2 = self.ln_after_mutilatte(out2)  # Apply BN after MultiheadAttention\n",
    "        out2 = self.avg_pool(out2.permute(0, 2, 1)).squeeze()\n",
    "        out2 = self.flatten(out2)\n",
    "        out2 = F.gelu(out2)\n",
    "\n",
    "        out2 = self.fc(out2)  # 句子最后时刻的 hidden state\n",
    "        return out2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:44.680774Z",
     "start_time": "2024-03-17T13:12:44.672132Z"
    }
   },
   "id": "7356afec4a9de110"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_config = ModelConfig(freeze=False)\n",
    "model = Model(model_config, data_config).to(data_config.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:53.121667Z",
     "start_time": "2024-03-17T13:12:49.501435Z"
    }
   },
   "id": "d0df6d80876a031a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randint(1, 10, [2, 30]).to(data_config.device)).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:54.602370Z",
     "start_time": "2024-03-17T13:12:54.386147Z"
    }
   },
   "id": "aaffb22c7d469f51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_network(model, method='xavier', exclude='embedding'):\n",
    "    for name, w in model.named_parameters():\n",
    "        if exclude not in name:  # 如果不是嵌入层\n",
    "            if 'weight' in name:  # weight 三种初始化方式\n",
    "                if method == 'xavier' and len(w.size() < 2):\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:  # bias 置0\n",
    "                nn.init.constant_(w, 0)\n",
    "            else:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f15fb82b21ae5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_network(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66db72222568e3af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237c62d2a30fbecf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设你的输入是一个大小为[2, 30, 100]的tensor\n",
    "input_tensor = torch.randn(2, 30, 100)\n",
    "\n",
    "# 执行最大池化操作，保留最大的两个值\n",
    "output_tensor = F.max_pool1d(input_tensor, kernel_size=2, stride=1)\n",
    "\n",
    "print(output_tensor.shape)  # 输出应为[2, 2, 100]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8bbd295da22dd87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\",\n",
    "                       data_files={\"train\": \"./ship_data/train_dataset.csv\", \"test\": \"./ship_data/test_dataset.csv\",\n",
    "                                   \"val\": \"./ship_data/val_dataset.csv\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8263d10d724eef20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a40b64fce48c7dab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4834be11c449021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers = list(model.children())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6a00f11be1db3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523045592d3523d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "summary(model, input_size=(batch_size, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9dd980a8c55c8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2c88dc8d3d46ded"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f45002109aea190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "out = token.encode('今天是个好日子')\n",
    "token.decode(out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14962731d7883467"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zidian = token.get_vocab()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb5745a89621aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "tokenizer = lambda x: x.split('|')  # word-level\n",
    "vocab = pkl.load(open('./ship_data/pre_data/vocab.pkl', 'rb'))  # 打开词表\n",
    "class_list = [x.strip() for x in\n",
    "              open(os.path.join('./ship_data/', 'pre_data', 'class.txt'), encoding='utf-8').readlines()]\n",
    "class_int_dict = {item: i for i, item in enumerate(class_list)}\n",
    "df = pd.read_csv('./ship_data/old_data/val_dataset.csv', usecols=['path', 'cluster'])  # 读取csv\n",
    "print(class_int_dict)\n",
    "contents = []\n",
    "pad_size = 30\n",
    "for index, row in df.iterrows():\n",
    "    content, label = row['path'], row['cluster']\n",
    "    token = tokenizer(content)\n",
    "    seq_len = len(token)\n",
    "    if seq_len < pad_size:\n",
    "        token.extend(['PAD'] * (pad_size - len(token)))\n",
    "    else:\n",
    "        token = token[:pad_size]\n",
    "        seq_len = pad_size\n",
    "    words_line = []\n",
    "    for word in token:\n",
    "        words_line.append(vocab.get(word, vocab.get('UNK')))\n",
    "    contents.append((words_line, class_int_dict[label], seq_len))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad9e63e6d920c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 将列表转换为 Pandas 数据框\n",
    "df = pd.DataFrame(contents, columns=['path', 'cluster', 'length'])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df.to_csv('val_dataset.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdf91dded7d019d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 指定CSV文件路径\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# 打开或创建CSV文件，并写入数据\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # 逐行写入数据\n",
    "    for row in contents:\n",
    "        csv_writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d90e42778fbebf17"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('./ship_data/test_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:11:54.066136Z",
     "start_time": "2023-12-13T10:11:53.851111900Z"
    }
   },
   "id": "58cb2b6fe9a4d485"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "         MaxPool2d-3           [-1, 64, 56, 56]               0\n",
      "            Conv2d-4           [-1, 64, 56, 56]           4,160\n",
      "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
      "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 56, 56]             384\n",
      "         MaxPool2d-8          [-1, 192, 28, 28]               0\n",
      "            Conv2d-9           [-1, 64, 28, 28]          12,352\n",
      "      BatchNorm2d-10           [-1, 64, 28, 28]             128\n",
      "            ReLU6-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 96, 28, 28]          18,528\n",
      "      BatchNorm2d-13           [-1, 96, 28, 28]             192\n",
      "            ReLU6-14           [-1, 96, 28, 28]               0\n",
      "           Conv2d-15          [-1, 128, 28, 28]         110,720\n",
      "      BatchNorm2d-16          [-1, 128, 28, 28]             256\n",
      "            ReLU6-17          [-1, 128, 28, 28]               0\n",
      "           Conv2d-18           [-1, 16, 28, 28]           3,088\n",
      "      BatchNorm2d-19           [-1, 16, 28, 28]              32\n",
      "            ReLU6-20           [-1, 16, 28, 28]               0\n",
      "           Conv2d-21           [-1, 32, 28, 28]          12,832\n",
      "      BatchNorm2d-22           [-1, 32, 28, 28]              64\n",
      "            ReLU6-23           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 192, 28, 28]               0\n",
      "           Conv2d-25           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-26           [-1, 32, 28, 28]              64\n",
      "            ReLU6-27           [-1, 32, 28, 28]               0\n",
      "InceptionV1Module-28          [-1, 256, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "            ReLU6-31          [-1, 128, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]          32,896\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "            ReLU6-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 192, 28, 28]         221,376\n",
      "      BatchNorm2d-36          [-1, 192, 28, 28]             384\n",
      "            ReLU6-37          [-1, 192, 28, 28]               0\n",
      "           Conv2d-38           [-1, 32, 28, 28]           8,224\n",
      "      BatchNorm2d-39           [-1, 32, 28, 28]              64\n",
      "            ReLU6-40           [-1, 32, 28, 28]               0\n",
      "           Conv2d-41           [-1, 96, 28, 28]          76,896\n",
      "      BatchNorm2d-42           [-1, 96, 28, 28]             192\n",
      "            ReLU6-43           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-44          [-1, 256, 28, 28]               0\n",
      "           Conv2d-45           [-1, 64, 28, 28]          16,448\n",
      "      BatchNorm2d-46           [-1, 64, 28, 28]             128\n",
      "            ReLU6-47           [-1, 64, 28, 28]               0\n",
      "InceptionV1Module-48          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-49          [-1, 480, 14, 14]               0\n",
      "           Conv2d-50          [-1, 192, 14, 14]          92,352\n",
      "      BatchNorm2d-51          [-1, 192, 14, 14]             384\n",
      "            ReLU6-52          [-1, 192, 14, 14]               0\n",
      "           Conv2d-53           [-1, 96, 14, 14]          46,176\n",
      "      BatchNorm2d-54           [-1, 96, 14, 14]             192\n",
      "            ReLU6-55           [-1, 96, 14, 14]               0\n",
      "           Conv2d-56          [-1, 208, 14, 14]         179,920\n",
      "      BatchNorm2d-57          [-1, 208, 14, 14]             416\n",
      "            ReLU6-58          [-1, 208, 14, 14]               0\n",
      "           Conv2d-59           [-1, 16, 14, 14]           7,696\n",
      "      BatchNorm2d-60           [-1, 16, 14, 14]              32\n",
      "            ReLU6-61           [-1, 16, 14, 14]               0\n",
      "           Conv2d-62           [-1, 48, 14, 14]          19,248\n",
      "      BatchNorm2d-63           [-1, 48, 14, 14]              96\n",
      "            ReLU6-64           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-65          [-1, 480, 14, 14]               0\n",
      "           Conv2d-66           [-1, 64, 14, 14]          30,784\n",
      "      BatchNorm2d-67           [-1, 64, 14, 14]             128\n",
      "            ReLU6-68           [-1, 64, 14, 14]               0\n",
      "InceptionV1Module-69          [-1, 512, 14, 14]               0\n",
      "           Conv2d-70          [-1, 160, 14, 14]          82,080\n",
      "      BatchNorm2d-71          [-1, 160, 14, 14]             320\n",
      "            ReLU6-72          [-1, 160, 14, 14]               0\n",
      "           Conv2d-73          [-1, 112, 14, 14]          57,456\n",
      "      BatchNorm2d-74          [-1, 112, 14, 14]             224\n",
      "            ReLU6-75          [-1, 112, 14, 14]               0\n",
      "           Conv2d-76          [-1, 224, 14, 14]         226,016\n",
      "      BatchNorm2d-77          [-1, 224, 14, 14]             448\n",
      "            ReLU6-78          [-1, 224, 14, 14]               0\n",
      "           Conv2d-79           [-1, 24, 14, 14]          12,312\n",
      "      BatchNorm2d-80           [-1, 24, 14, 14]              48\n",
      "            ReLU6-81           [-1, 24, 14, 14]               0\n",
      "           Conv2d-82           [-1, 64, 14, 14]          38,464\n",
      "      BatchNorm2d-83           [-1, 64, 14, 14]             128\n",
      "            ReLU6-84           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-85          [-1, 512, 14, 14]               0\n",
      "           Conv2d-86           [-1, 64, 14, 14]          32,832\n",
      "      BatchNorm2d-87           [-1, 64, 14, 14]             128\n",
      "            ReLU6-88           [-1, 64, 14, 14]               0\n",
      "InceptionV1Module-89          [-1, 512, 14, 14]               0\n",
      "           Conv2d-90          [-1, 128, 14, 14]          65,664\n",
      "      BatchNorm2d-91          [-1, 128, 14, 14]             256\n",
      "            ReLU6-92          [-1, 128, 14, 14]               0\n",
      "           Conv2d-93          [-1, 128, 14, 14]          65,664\n",
      "      BatchNorm2d-94          [-1, 128, 14, 14]             256\n",
      "            ReLU6-95          [-1, 128, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "            ReLU6-98          [-1, 256, 14, 14]               0\n",
      "           Conv2d-99           [-1, 24, 14, 14]          12,312\n",
      "     BatchNorm2d-100           [-1, 24, 14, 14]              48\n",
      "           ReLU6-101           [-1, 24, 14, 14]               0\n",
      "          Conv2d-102           [-1, 64, 14, 14]          38,464\n",
      "     BatchNorm2d-103           [-1, 64, 14, 14]             128\n",
      "           ReLU6-104           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-105          [-1, 512, 14, 14]               0\n",
      "          Conv2d-106           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-107           [-1, 64, 14, 14]             128\n",
      "           ReLU6-108           [-1, 64, 14, 14]               0\n",
      "InceptionV1Module-109          [-1, 512, 14, 14]               0\n",
      "          Conv2d-110          [-1, 112, 14, 14]          57,456\n",
      "     BatchNorm2d-111          [-1, 112, 14, 14]             224\n",
      "           ReLU6-112          [-1, 112, 14, 14]               0\n",
      "          Conv2d-113          [-1, 144, 14, 14]          73,872\n",
      "     BatchNorm2d-114          [-1, 144, 14, 14]             288\n",
      "           ReLU6-115          [-1, 144, 14, 14]               0\n",
      "          Conv2d-116          [-1, 288, 14, 14]         373,536\n",
      "     BatchNorm2d-117          [-1, 288, 14, 14]             576\n",
      "           ReLU6-118          [-1, 288, 14, 14]               0\n",
      "          Conv2d-119           [-1, 32, 14, 14]          16,416\n",
      "     BatchNorm2d-120           [-1, 32, 14, 14]              64\n",
      "           ReLU6-121           [-1, 32, 14, 14]               0\n",
      "          Conv2d-122           [-1, 64, 14, 14]          51,264\n",
      "     BatchNorm2d-123           [-1, 64, 14, 14]             128\n",
      "           ReLU6-124           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-125          [-1, 512, 14, 14]               0\n",
      "          Conv2d-126           [-1, 64, 14, 14]          32,832\n",
      "     BatchNorm2d-127           [-1, 64, 14, 14]             128\n",
      "           ReLU6-128           [-1, 64, 14, 14]               0\n",
      "InceptionV1Module-129          [-1, 528, 14, 14]               0\n",
      "          Conv2d-130          [-1, 256, 14, 14]         135,424\n",
      "     BatchNorm2d-131          [-1, 256, 14, 14]             512\n",
      "           ReLU6-132          [-1, 256, 14, 14]               0\n",
      "          Conv2d-133          [-1, 160, 14, 14]          84,640\n",
      "     BatchNorm2d-134          [-1, 160, 14, 14]             320\n",
      "           ReLU6-135          [-1, 160, 14, 14]               0\n",
      "          Conv2d-136          [-1, 320, 14, 14]         461,120\n",
      "     BatchNorm2d-137          [-1, 320, 14, 14]             640\n",
      "           ReLU6-138          [-1, 320, 14, 14]               0\n",
      "          Conv2d-139           [-1, 32, 14, 14]          16,928\n",
      "     BatchNorm2d-140           [-1, 32, 14, 14]              64\n",
      "           ReLU6-141           [-1, 32, 14, 14]               0\n",
      "          Conv2d-142          [-1, 128, 14, 14]         102,528\n",
      "     BatchNorm2d-143          [-1, 128, 14, 14]             256\n",
      "           ReLU6-144          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-145          [-1, 528, 14, 14]               0\n",
      "          Conv2d-146          [-1, 128, 14, 14]          67,712\n",
      "     BatchNorm2d-147          [-1, 128, 14, 14]             256\n",
      "           ReLU6-148          [-1, 128, 14, 14]               0\n",
      "InceptionV1Module-149          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-150            [-1, 832, 7, 7]               0\n",
      "          Conv2d-151            [-1, 256, 7, 7]         213,248\n",
      "     BatchNorm2d-152            [-1, 256, 7, 7]             512\n",
      "           ReLU6-153            [-1, 256, 7, 7]               0\n",
      "          Conv2d-154            [-1, 160, 7, 7]         133,280\n",
      "     BatchNorm2d-155            [-1, 160, 7, 7]             320\n",
      "           ReLU6-156            [-1, 160, 7, 7]               0\n",
      "          Conv2d-157            [-1, 320, 7, 7]         461,120\n",
      "     BatchNorm2d-158            [-1, 320, 7, 7]             640\n",
      "           ReLU6-159            [-1, 320, 7, 7]               0\n",
      "          Conv2d-160             [-1, 32, 7, 7]          26,656\n",
      "     BatchNorm2d-161             [-1, 32, 7, 7]              64\n",
      "           ReLU6-162             [-1, 32, 7, 7]               0\n",
      "          Conv2d-163            [-1, 128, 7, 7]         102,528\n",
      "     BatchNorm2d-164            [-1, 128, 7, 7]             256\n",
      "           ReLU6-165            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-166            [-1, 832, 7, 7]               0\n",
      "          Conv2d-167            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-168            [-1, 128, 7, 7]             256\n",
      "           ReLU6-169            [-1, 128, 7, 7]               0\n",
      "InceptionV1Module-170            [-1, 832, 7, 7]               0\n",
      "          Conv2d-171            [-1, 384, 7, 7]         319,872\n",
      "     BatchNorm2d-172            [-1, 384, 7, 7]             768\n",
      "           ReLU6-173            [-1, 384, 7, 7]               0\n",
      "          Conv2d-174            [-1, 192, 7, 7]         159,936\n",
      "     BatchNorm2d-175            [-1, 192, 7, 7]             384\n",
      "           ReLU6-176            [-1, 192, 7, 7]               0\n",
      "          Conv2d-177            [-1, 384, 7, 7]         663,936\n",
      "     BatchNorm2d-178            [-1, 384, 7, 7]             768\n",
      "           ReLU6-179            [-1, 384, 7, 7]               0\n",
      "          Conv2d-180             [-1, 48, 7, 7]          39,984\n",
      "     BatchNorm2d-181             [-1, 48, 7, 7]              96\n",
      "           ReLU6-182             [-1, 48, 7, 7]               0\n",
      "          Conv2d-183            [-1, 128, 7, 7]         153,728\n",
      "     BatchNorm2d-184            [-1, 128, 7, 7]             256\n",
      "           ReLU6-185            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-186            [-1, 832, 7, 7]               0\n",
      "          Conv2d-187            [-1, 128, 7, 7]         106,624\n",
      "     BatchNorm2d-188            [-1, 128, 7, 7]             256\n",
      "           ReLU6-189            [-1, 128, 7, 7]               0\n",
      "InceptionV1Module-190           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-191           [-1, 1024, 1, 1]               0\n",
      "         Dropout-192           [-1, 1024, 1, 1]               0\n",
      "          Linear-193                 [-1, 1000]       1,025,000\n",
      "       AvgPool2d-194            [-1, 512, 4, 4]               0\n",
      "          Conv2d-195            [-1, 128, 4, 4]          65,664\n",
      "     BatchNorm2d-196            [-1, 128, 4, 4]             256\n",
      "           ReLU6-197            [-1, 128, 4, 4]               0\n",
      "          Linear-198                 [-1, 1024]       2,098,176\n",
      "           ReLU6-199                 [-1, 1024]               0\n",
      "         Dropout-200                 [-1, 1024]               0\n",
      "          Linear-201                 [-1, 1000]       1,025,000\n",
      "    InceptionAux-202                 [-1, 1000]               0\n",
      "       AvgPool2d-203            [-1, 528, 4, 4]               0\n",
      "          Conv2d-204            [-1, 128, 4, 4]          67,712\n",
      "     BatchNorm2d-205            [-1, 128, 4, 4]             256\n",
      "           ReLU6-206            [-1, 128, 4, 4]               0\n",
      "          Linear-207                 [-1, 1024]       2,098,176\n",
      "           ReLU6-208                 [-1, 1024]               0\n",
      "         Dropout-209                 [-1, 1024]               0\n",
      "          Linear-210                 [-1, 1000]       1,025,000\n",
      "    InceptionAux-211                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 13,393,352\n",
      "Trainable params: 13,393,352\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 82.15\n",
      "Params size (MB): 51.09\n",
      "Estimated Total Size (MB): 133.82\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "'InceptionV1.png'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.Inception import InceptionV1\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from graphviz import Digraph\n",
    "\n",
    "# 定义InceptionV1模型\n",
    "model = InceptionV1()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 生成网络结构摘要\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\"Create a graph of the PyTorch autograd graph.\"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(map(str, size))+')'\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        if hasattr(u[0], 'variable'):\n",
    "                            dot.edge(str(id(u[0].variable)), str(id(var)))\n",
    "                        else:\n",
    "                            dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    if isinstance(var, tuple):\n",
    "        for v in var:\n",
    "            add_nodes(v.grad_fn)\n",
    "    else:\n",
    "        add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "\n",
    "# 绘制网络结构图\n",
    "inputs = torch.randn(1, 3, 224, 224).to(device)\n",
    "y = model(inputs)\n",
    "g = make_dot(y)\n",
    "g.render('InceptionV1', format='png', cleanup=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T07:26:40.063800Z",
     "start_time": "2024-03-20T07:26:39.299874Z"
    }
   },
   "id": "9f1ab9622bb87e1d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 1, 5, 5])\n",
      "Output values:\n",
      "tensor([[[[21.9404, 29.9404, 30.9404, 23.9404, 24.9404],\n",
      "          [31.9404, 41.9404, 57.9404, 43.9404, 47.9404],\n",
      "          [47.9404, 53.9404, 69.9404, 30.9404, 39.9404],\n",
      "          [45.9404, 56.9404, 65.9404, 27.9404, 31.9404],\n",
      "          [50.9404, 28.9404, 59.9404,  9.9404, 32.9404]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 创建自定义输入张量\n",
    "input_data = torch.tensor([[[[0.0, 1.0, 2.0, 3.0, 3.0],\n",
    "                             [4.0, 5.0, 6.0, 7.0, 7.0],\n",
    "                             [8.0, 9.0, 4.0, 2.0, 4.0],\n",
    "                             [1.0, 3.0, 5.0, 5.0, 5.0],\n",
    "                             [2.0, 4.0, 7.0, 0.0, 5.0]]]])\n",
    "\n",
    "# 创建自定义卷积核张量\n",
    "kernel_data = torch.tensor([[[[0.0, 1.0, 4.0],\n",
    "                              [2.0, 3.0, 3.0],\n",
    "                              [1.0, 2.0, 0.0]]]])\n",
    "\n",
    "# 创建卷积层\n",
    "model = nn.Conv2d(1, 1, kernel_size=(3, 3), padding=2, stride=1, dilation=2)\n",
    "\n",
    "# 将自定义的卷积核张量加载到模型的权重中\n",
    "model.weight.data = kernel_data\n",
    "\n",
    "# 执行卷积操作\n",
    "output = model(input_data)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\")\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T16:02:20.335786Z",
     "start_time": "2024-03-20T16:02:20.328281Z"
    }
   },
   "id": "f632cd688c19cf5",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4be7ea98482d6fe0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
