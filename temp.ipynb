{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import models.ShipRNN as model\n",
    "\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "torch.backends.cudnn.benchmark = False\n",
    "UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b0570a3e0c8f1240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import BertDataConfig, BertDataset\n",
    "\n",
    "data_config = BertDataConfig()\n",
    "val_dataset = BertDataset(data_config, data_class='val')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda7eed9a6f00df6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import DataConfig\n",
    "\n",
    "data_config = DataConfig('word2vec')\n",
    "model_config = model.ModelConfig()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af892feebfe7d54d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_config, data_config):\n",
    "        super(Model, self).__init__()\n",
    "        # Existing code\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            data_config.embedding_pretrained,\n",
    "            freeze=False) if data_config.embedding_pretrained is not None else nn.Embedding(data_config.n_vocab,\n",
    "                                                                                            data_config.embed,\n",
    "                                                                                            padding_idx=data_config.n_vocab - 1)\n",
    "        # New BatchNorm layer after embedding\n",
    "        self.bn_after_embedding = nn.BatchNorm1d(data_config.embed)\n",
    "\n",
    "        self.lstm = nn.LSTM(data_config.embed, model_config.hidden_size, model_config.num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=model_config.dropout)\n",
    "        self.bn = nn.BatchNorm1d(model_config.hidden_size * 2)\n",
    "        self.avg_pool = nn.AvgPool1d(data_config.pad_size // 4)\n",
    "        self.mutilatte = nn.MultiheadAttention(embed_dim=model_config.hidden_size * 2 + data_config.embed, num_heads=6,\n",
    "                                               batch_first=True)\n",
    "\n",
    "        # New BatchNorm layer after MultiheadAttention\n",
    "        self.bn_after_mutilatte = nn.BatchNorm1d(model_config.hidden_size * 2 + data_config.embed)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4 * (model_config.hidden_size * 2 + data_config.embed), data_config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)  # [batch_size, seq_len, embeding]\n",
    "        embed = self.bn_after_embedding(embed.permute(0, 2, 1)).permute(0, 2, 1)  # Apply BN after embedding\n",
    "        out, _ = self.lstm(embed)  # 左右双向\n",
    "        out1 = torch.cat((embed, out), 2)\n",
    "        out1 = F.gelu(out1)\n",
    "        out2, _ = self.mutilatte(out1, out1, out1)\n",
    "        out2 = self.bn_after_mutilatte(out2.permute(0, 2, 1))  # Apply BN after MultiheadAttention\n",
    "        out2 = self.avg_pool(out2).squeeze()\n",
    "        out2 = self.flatten(out2)\n",
    "        out2 = F.gelu(out2)\n",
    "        print(out2.shape)\n",
    "        out2 = self.fc(out2)  # 句子最后时刻的 hidden state\n",
    "        return out2\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7356afec4a9de110"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model(model_config, data_config).to(data_config.device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0df6d80876a031a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model(torch.randint(1, 10, [2, 30]).to(data_config.device)).size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaffb22c7d469f51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_network(model, method='xavier', exclude='embedding'):\n",
    "    for name, w in model.named_parameters():\n",
    "        if exclude not in name:  # 如果不是嵌入层\n",
    "            if 'weight' in name:  # weight 三种初始化方式\n",
    "                if method == 'xavier' and len(w.size() < 2):\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:  # bias 置0\n",
    "                nn.init.constant_(w, 0)\n",
    "            else:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f15fb82b21ae5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_network(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66db72222568e3af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237c62d2a30fbecf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = './test_data/'\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(f'{path}chn_text.csv')  # 替换为你的CSV文件路径\n",
    "\n",
    "# 划分数据集\n",
    "train_df, temp_df = train_test_split(df, test_size=0.1, random_state=3407)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=3407)\n",
    "\n",
    "# 保存划分后的数据集为新的CSV文件\n",
    "train_df.to_csv(f'{path}train_dataset.csv', index=False)\n",
    "val_df.to_csv(f'{path}val_dataset.csv', index=False)\n",
    "test_df.to_csv(f'{path}test_dataset.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7af81258ec20d49a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设你的输入是一个大小为[2, 30, 100]的tensor\n",
    "input_tensor = torch.randn(2, 30, 100)\n",
    "\n",
    "# 执行最大池化操作，保留最大的两个值\n",
    "output_tensor = F.max_pool1d(input_tensor, kernel_size=2, stride=1)\n",
    "\n",
    "print(output_tensor.shape)  # 输出应为[2, 2, 100]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8bbd295da22dd87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\",\n",
    "                       data_files={\"train\": \"./ship_data/train_dataset.csv\", \"test\": \"./ship_data/test_dataset.csv\",\n",
    "                                   \"val\": \"./ship_data/val_dataset.csv\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8263d10d724eef20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a40b64fce48c7dab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4834be11c449021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers = list(model.children())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6a00f11be1db3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523045592d3523d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "summary(model, input_size=(batch_size, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9dd980a8c55c8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2c88dc8d3d46ded"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f45002109aea190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "out = token.encode('今天是个好日子')\n",
    "token.decode(out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14962731d7883467"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zidian = token.get_vocab()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb5745a89621aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "tokenizer = lambda x: x.split('|')  # word-level\n",
    "vocab = pkl.load(open('./ship_data/pre_data/vocab.pkl', 'rb'))  # 打开词表\n",
    "class_list = [x.strip() for x in\n",
    "              open(os.path.join('./ship_data/', 'pre_data', 'class.txt'), encoding='utf-8').readlines()]\n",
    "class_int_dict = {item: i for i, item in enumerate(class_list)}\n",
    "df = pd.read_csv('./ship_data/old_data/val_dataset.csv', usecols=['path', 'cluster'])  # 读取csv\n",
    "print(class_int_dict)\n",
    "contents = []\n",
    "pad_size = 30\n",
    "for index, row in df.iterrows():\n",
    "    content, label = row['path'], row['cluster']\n",
    "    token = tokenizer(content)\n",
    "    seq_len = len(token)\n",
    "    if seq_len < pad_size:\n",
    "        token.extend(['PAD'] * (pad_size - len(token)))\n",
    "    else:\n",
    "        token = token[:pad_size]\n",
    "        seq_len = pad_size\n",
    "    words_line = []\n",
    "    for word in token:\n",
    "        words_line.append(vocab.get(word, vocab.get('UNK')))\n",
    "    contents.append((words_line, class_int_dict[label], seq_len))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad9e63e6d920c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 将列表转换为 Pandas 数据框\n",
    "df = pd.DataFrame(contents, columns=['path', 'cluster', 'length'])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df.to_csv('val_dataset.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdf91dded7d019d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 指定CSV文件路径\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# 打开或创建CSV文件，并写入数据\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # 逐行写入数据\n",
    "    for row in contents:\n",
    "        csv_writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d90e42778fbebf17"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('./ship_data/test_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:11:54.066136Z",
     "start_time": "2023-12-13T10:11:53.851111900Z"
    }
   },
   "id": "58cb2b6fe9a4d485"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "cluster\n散杂货船     44333\n渔船       40276\n集装箱船     18656\n油船        6458\n液体散货船     5919\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['cluster'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:11:54.081058900Z",
     "start_time": "2023-12-13T10:11:54.064136300Z"
    }
   },
   "id": "9f1ab9622bb87e1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f632cd688c19cf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
