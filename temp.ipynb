{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "torch.backends.cudnn.benchmark = False\n",
    "UNK, PAD = '<UNK>', '<PAD>'  # 未知字，padding符号"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:34.962559Z",
     "start_time": "2024-03-17T13:12:33.154552Z"
    }
   },
   "id": "b0570a3e0c8f1240"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from utils import BertDataConfig, BertDataset\n",
    "# \n",
    "# data_config = BertDataConfig()\n",
    "# val_dataset = BertDataset(data_config, data_class='val')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T14:30:18.426679400Z",
     "start_time": "2023-12-14T14:30:18.415171900Z"
    }
   },
   "id": "cda7eed9a6f00df6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import DataConfig\n",
    "\n",
    "data_config = DataConfig('word2vec', 50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:41.996797Z",
     "start_time": "2024-03-17T13:12:41.380420Z"
    }
   },
   "id": "af892feebfe7d54d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ModelConfig(object):\n",
    "    \"\"\"配置参数\"\"\"\n",
    "\n",
    "    def __init__(self, freeze, notes=''):\n",
    "        self.model_name = 'ShipRNN'\n",
    "        self.save_path = f'./result/{self.model_name}_{notes}.ckpt'  # 模型训练结果\n",
    "        self.log_path = './tf_log/' + self.model_name\n",
    "\n",
    "        self.dropout = 0.5  # 随机失活\n",
    "        self.hidden_size = 256  # lstm隐藏层\n",
    "        self.num_layers = 2  # lstm层数\n",
    "        self.num_heads = 6\n",
    "        self.freeze = freeze\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_config, data_config):\n",
    "        super(Model, self).__init__()\n",
    "        # Existing code\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            data_config.embedding_pretrained,\n",
    "            freeze=model_config.freeze) if data_config.embedding_pretrained is not None else nn.Embedding(\n",
    "            data_config.n_vocab,\n",
    "            data_config.embed,\n",
    "            padding_idx=data_config.n_vocab - 1)\n",
    "        # New BatchNorm layer after embedding\n",
    "        self.ln_after_embedding = nn.LayerNorm(data_config.embed)\n",
    "\n",
    "        self.lstm = nn.LSTM(data_config.embed, model_config.hidden_size, model_config.num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=model_config.dropout)\n",
    "        self.avg_pool = nn.AvgPool1d(data_config.pad_size // 4)\n",
    "        self.value = ((\n",
    "                              model_config.hidden_size * 2 + data_config.embed) // model_config.num_heads) * model_config.num_heads\n",
    "        self.mutilatte = nn.MultiheadAttention(embed_dim=self.value,\n",
    "                                               num_heads=model_config.num_heads,\n",
    "                                               batch_first=True)\n",
    "\n",
    "        self.ln_after_mutilatte = nn.LayerNorm(self.value)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(4 * self.value, data_config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)  # [batch_size, seq_len, embeding]\n",
    "        embed = self.ln_after_embedding(embed)  # Apply BN after embedding\n",
    "        out, _ = self.lstm(embed)  # 左右双向\n",
    "        out1 = torch.cat((embed, out), 2)\n",
    "        out1 = F.gelu(out1[:, :, :self.value])\n",
    "        out2, _ = self.mutilatte(out1, out1, out1)\n",
    "        out2 = self.ln_after_mutilatte(out2)  # Apply BN after MultiheadAttention\n",
    "        out2 = self.avg_pool(out2.permute(0, 2, 1)).squeeze()\n",
    "        out2 = self.flatten(out2)\n",
    "        out2 = F.gelu(out2)\n",
    "\n",
    "        out2 = self.fc(out2)  # 句子最后时刻的 hidden state\n",
    "        return out2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:44.680774Z",
     "start_time": "2024-03-17T13:12:44.672132Z"
    }
   },
   "id": "7356afec4a9de110"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_config = ModelConfig(freeze=False)\n",
    "model = Model(model_config, data_config).to(data_config.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:53.121667Z",
     "start_time": "2024-03-17T13:12:49.501435Z"
    }
   },
   "id": "d0df6d80876a031a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randint(1, 10, [2, 30]).to(data_config.device)).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T13:12:54.602370Z",
     "start_time": "2024-03-17T13:12:54.386147Z"
    }
   },
   "id": "aaffb22c7d469f51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_network(model, method='xavier', exclude='embedding'):\n",
    "    for name, w in model.named_parameters():\n",
    "        if exclude not in name:  # 如果不是嵌入层\n",
    "            if 'weight' in name:  # weight 三种初始化方式\n",
    "                if method == 'xavier' and len(w.size() < 2):\n",
    "                    nn.init.xavier_normal_(w)\n",
    "                elif method == 'kaiming':\n",
    "                    nn.init.kaiming_normal_(w)\n",
    "                else:\n",
    "                    nn.init.normal_(w)\n",
    "            elif 'bias' in name:  # bias 置0\n",
    "                nn.init.constant_(w, 0)\n",
    "            else:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95f15fb82b21ae5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_network(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66db72222568e3af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "237c62d2a30fbecf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设你的输入是一个大小为[2, 30, 100]的tensor\n",
    "input_tensor = torch.randn(2, 30, 100)\n",
    "\n",
    "# 执行最大池化操作，保留最大的两个值\n",
    "output_tensor = F.max_pool1d(input_tensor, kernel_size=2, stride=1)\n",
    "\n",
    "print(output_tensor.shape)  # 输出应为[2, 2, 100]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8bbd295da22dd87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\",\n",
    "                       data_files={\"train\": \"./ship_data/train_dataset.csv\", \"test\": \"./ship_data/test_dataset.csv\",\n",
    "                                   \"val\": \"./ship_data/val_dataset.csv\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8263d10d724eef20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a40b64fce48c7dab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4834be11c449021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers = list(model.children())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6a00f11be1db3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523045592d3523d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "summary(model, input_size=(batch_size, 30), dtypes=[torch.long])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd9dd980a8c55c8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "type(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2c88dc8d3d46ded"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f45002109aea190"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "out = token.encode('今天是个好日子')\n",
    "token.decode(out)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14962731d7883467"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zidian = token.get_vocab()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb5745a89621aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "tokenizer = lambda x: x.split('|')  # word-level\n",
    "vocab = pkl.load(open('./ship_data/pre_data/vocab.pkl', 'rb'))  # 打开词表\n",
    "class_list = [x.strip() for x in\n",
    "              open(os.path.join('./ship_data/', 'pre_data', 'class.txt'), encoding='utf-8').readlines()]\n",
    "class_int_dict = {item: i for i, item in enumerate(class_list)}\n",
    "df = pd.read_csv('./ship_data/old_data/val_dataset.csv', usecols=['path', 'cluster'])  # 读取csv\n",
    "print(class_int_dict)\n",
    "contents = []\n",
    "pad_size = 30\n",
    "for index, row in df.iterrows():\n",
    "    content, label = row['path'], row['cluster']\n",
    "    token = tokenizer(content)\n",
    "    seq_len = len(token)\n",
    "    if seq_len < pad_size:\n",
    "        token.extend(['PAD'] * (pad_size - len(token)))\n",
    "    else:\n",
    "        token = token[:pad_size]\n",
    "        seq_len = pad_size\n",
    "    words_line = []\n",
    "    for word in token:\n",
    "        words_line.append(vocab.get(word, vocab.get('UNK')))\n",
    "    contents.append((words_line, class_int_dict[label], seq_len))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad9e63e6d920c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 将列表转换为 Pandas 数据框\n",
    "df = pd.DataFrame(contents, columns=['path', 'cluster', 'length'])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df.to_csv('val_dataset.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdf91dded7d019d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 指定CSV文件路径\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# 打开或创建CSV文件，并写入数据\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # 逐行写入数据\n",
    "    for row in contents:\n",
    "        csv_writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d90e42778fbebf17"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('./ship_data/test_dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T10:11:54.066136Z",
     "start_time": "2023-12-13T10:11:53.851111900Z"
    }
   },
   "id": "58cb2b6fe9a4d485"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  8,  6],\n",
      "          [28, 36,  4],\n",
      "          [ 2,  7,  0]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "input_matrix = torch.tensor([[0, 1, 2, 3],\n",
    "                             [4, 5, 6, 7],\n",
    "                             [8, 9, 4, 2],\n",
    "                             [2, 3, 7, 5]])\n",
    "\n",
    "# 创建卷积核\n",
    "conv_kernel = torch.tensor([[0, 1],\n",
    "                            [2, 3]])\n",
    "\n",
    "# 使用 F.conv2d 进行卷积操作\n",
    "output_matrix = F.conv2d(input_matrix.view(1, 1, 4, 4), conv_kernel.view(1, 1, 2, 2),stride=2,padding=1)\n",
    "\n",
    "print(output_matrix)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T07:48:17.732411200Z",
     "start_time": "2023-12-16T07:48:17.720643800Z"
    }
   },
   "id": "9f1ab9622bb87e1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f632cd688c19cf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
