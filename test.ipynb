{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:33:20.661174600Z",
     "start_time": "2023-11-20T11:33:17.263305400Z"
    }
   },
   "outputs": [],
   "source": [
    "from importlib import import_module\n",
    "from torch.utils.data import DataLoader\n",
    "from train_eval import test\n",
    "from utils import CustomDataset, DataConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def call(model_path, model_name='TextCNN', dataset='ship_data',\n",
    "         embedding='embedding.npz'):\n",
    "    model_module = import_module(f'models.{model_name}')\n",
    "    model_config = model_module.Config()\n",
    "    data_config = DataConfig(dataset, embedding)\n",
    "    test_dataset = CustomDataset(data_config, data_class='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=model_config.batch_size)\n",
    "    model = model_module.Model(model_config, data_config).to(data_config.device)\n",
    "    test(data_config, model, test_loader, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:45:18.618943100Z",
     "start_time": "2023-11-20T11:45:18.606272600Z"
    }
   },
   "id": "8284de816861554b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.19,  Test Acc: 93.92%\n",
      "Precision, Recall and F1-Score...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        散杂货船     0.9092    0.9528    0.9305     44333\n",
      "          渔船     0.9736    0.9855    0.9795     40276\n",
      "        集装箱船     0.9330    0.9157    0.9243     18656\n",
      "          油船     0.9562    0.8018    0.8722      6458\n",
      "       液体散货船     0.9420    0.7466    0.8330      5919\n",
      "\n",
      "    accuracy                         0.9392    115642\n",
      "   macro avg     0.9428    0.8805    0.9079    115642\n",
      "weighted avg     0.9398    0.9392    0.9383    115642\n",
      "\n",
      "Confusion Matrix...\n",
      "[[42240   862   950   141   140]\n",
      " [  552 39691    15    12     6]\n",
      " [ 1461    59 17084     6    46]\n",
      " [ 1080    88    32  5178    80]\n",
      " [ 1127    66   229    78  4419]]\n"
     ]
    }
   ],
   "source": [
    "call(model_path='./result/TextCNN_单层嵌入层.ckpt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T11:45:28.727667100Z",
     "start_time": "2023-11-20T11:45:21.003659600Z"
    }
   },
   "id": "8c7a0b1ebdcb955a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=256 * 3 * 3, out_features=4096),  # 修改in_features以适应输入尺寸\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.Linear(in_features=4096, out_features=4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)\n",
    "        x = x.view(x.size(0), 256 * 3 * 3)  # 修改reshape的参数以适应输入尺寸\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T07:10:12.220939Z",
     "start_time": "2024-03-19T07:10:12.213973Z"
    }
   },
   "id": "d1b248c972a53370",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0064, -0.0140,  0.0149,  0.0145]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # 将图像转换为张量\n",
    "])\n",
    "\n",
    "# 2. 读取图像\n",
    "image = Image.open(\"./ship_data/pic_data/mmsi_50.png\")  # 替换\"example.jpg\"为你的图片路径\n",
    "\n",
    "# 3. 数据转换\n",
    "image = transform(image)\n",
    "# 添加一维\n",
    "image = image.unsqueeze(0)  # 在第0维度添加一维\n",
    "\n",
    "model=AlexNet()\n",
    "a=model(image)\n",
    "\n",
    "# 5. 显示图像张量的大小\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T07:10:31.382432Z",
     "start_time": "2024-03-19T07:10:31.257694Z"
    }
   },
   "id": "a3b1cdd2dc4079a9",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShipRNN 50 word2vec\n",
      "start read data...\n",
      "read data done...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "import models.ShipRNN as ShipRNN\n",
    "from train_eval import train, init_network, test\n",
    "from utils import CustomDataset, DataConfig\n",
    "# 随机种子设置\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed_all(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "embedding = 'word2vec'\n",
    "dim = 50\n",
    "model_name = 'ShipRNN'\n",
    "class_type = 'cluster'\n",
    "\n",
    "model_config = ShipRNN.ModelConfig(notes='')\n",
    "data_config = DataConfig(embedding, dim, class_type)\n",
    "print(model_name, data_config.dim, embedding)\n",
    "\n",
    "# 创建自定义数据集\n",
    "print('start read data...')\n",
    "train_dataset = CustomDataset(data_config, data_class='train')\n",
    "val_dataset = CustomDataset(data_config, data_class='val')\n",
    "test_dataset = CustomDataset(data_config, data_class='test')\n",
    "vocab = pkl.load(open(data_config.vocab_path, 'rb'))\n",
    "data_config.n_vocab = len(vocab)\n",
    "print('read data done...')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:20:29.608197Z",
     "start_time": "2024-03-19T10:19:39.500340Z"
    }
   },
   "id": "428ac05895f2b9bd",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=data_config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=data_config.batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=data_config.batch_size)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:20:38.665139Z",
     "start_time": "2024-03-19T10:20:38.661729Z"
    }
   },
   "id": "338b793e4d350838",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nAlexNet                                  [2, 5]                    --\n├─Sequential: 1-1                        [2, 256, 3, 3]            --\n│    └─Conv2d: 2-1                       [2, 96, 31, 28]           864\n│    └─ReLU: 2-2                         [2, 96, 31, 28]           --\n│    └─MaxPool2d: 2-3                    [2, 96, 15, 14]           --\n│    └─Conv2d: 2-4                       [2, 192, 15, 14]          165,888\n│    └─ReLU: 2-5                         [2, 192, 15, 14]          --\n│    └─MaxPool2d: 2-6                    [2, 192, 7, 7]            --\n│    └─Conv2d: 2-7                       [2, 384, 7, 7]            663,552\n│    └─ReLU: 2-8                         [2, 384, 7, 7]            --\n│    └─Conv2d: 2-9                       [2, 256, 7, 7]            884,736\n│    └─ReLU: 2-10                        [2, 256, 7, 7]            --\n│    └─Conv2d: 2-11                      [2, 256, 7, 7]            589,824\n│    └─ReLU: 2-12                        [2, 256, 7, 7]            --\n│    └─MaxPool2d: 2-13                   [2, 256, 3, 3]            --\n├─Sequential: 1-2                        [2, 5]                    --\n│    └─Dropout: 2-14                     [2, 2304]                 --\n│    └─Linear: 2-15                      [2, 4096]                 9,441,280\n│    └─Dropout: 2-16                     [2, 4096]                 --\n│    └─Linear: 2-17                      [2, 4096]                 16,781,312\n│    └─Linear: 2-18                      [2, 5]                    20,485\n==========================================================================================\nTotal params: 28,547,941\nTrainable params: 28,547,941\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 333.19\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 2.81\nParams size (MB): 114.19\nEstimated Total Size (MB): 117.01\n=========================================================================================="
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models.AlexNet as AlexNet\n",
    "# model = ShipRNN.Model(model_config, data_config).to(data_config.device)\n",
    "model = AlexNet.AlexNet(data_config)\n",
    "\n",
    "# 初始化模型参数\n",
    "\n",
    "init_network(model)\n",
    "summary(model, input_size=(2, 1, 31, 28), dtypes=[torch.float])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:23:42.173848Z",
     "start_time": "2024-03-19T10:23:39.578256Z"
    }
   },
   "id": "c991b756633de9dd",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch [1/100]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# 将测试结果写入文件\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Desktop\\deep_learning\\route_classification\\train_eval.py:59\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model_config, data_config, model, train_iter, dev_iter, notes)\u001B[0m\n\u001B[0;32m     56\u001B[0m train_acc \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39maccuracy_score(true, predic)\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# train_recall = metrics.recall_score(true, predic)\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# train_f1 = metrics.f1_score(true, predic)\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdev_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# Access accuracy and loss from the results dictionary\u001B[39;00m\n\u001B[0;32m     61\u001B[0m dev_acc \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\Desktop\\deep_learning\\route_classification\\train_eval.py:217\u001B[0m, in \u001B[0;36mevaluate\u001B[1;34m(config, model, data_iter, is_test)\u001B[0m\n\u001B[0;32m    215\u001B[0m predict_all \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    216\u001B[0m labels_all \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 217\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m data_iter:\n\u001B[0;32m    218\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    219\u001B[0m     y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(config\u001B[38;5;241m.\u001B[39mdevice)\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train(model_config, data_config, model, train_loader, val_loader, '')\n",
    "# 将测试结果写入文件\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T10:24:43.614603Z",
     "start_time": "2024-03-19T10:24:43.261036Z"
    }
   },
   "id": "45c52f003aabd706",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res, res1 = test(data_config, model, test_loader, model_path=model_config.save_path)\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.now()\n",
    "formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "with open(f'res_6/{model_config.model_name}_{notes}_{formatted_time}_{embedding}.txt', \"w\") as file:\n",
    "    file.write(str(res))\n",
    "    file.write(str(res1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29379d636e6eed8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
